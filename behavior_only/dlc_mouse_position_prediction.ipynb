{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886cb1fc-b2f1-4144-95c1-c499860cae2f",
   "metadata": {},
   "source": [
    "## Deeplabcut prediction of mouse position\n",
    "\n",
    "\n",
    "We use 2 dlc models to predict the position of the mouse in the `arena_top.cropped` and `positrack2` videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026f516d-9a31-4981-ad05-5910f1dd3d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilo/repo/analysis_jingjie/jingjie/autopi_mec_jingjie/autopi_mec/mouse_and_objects_position_tracking/setup_project.py:769: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit()\n",
      "/home/kilo/repo/analysis_jingjie/jingjie/autopi_mec_jingjie/autopi_mec/mouse_and_objects_position_tracking/setup_project.py:797: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit()\n",
      "/home/kilo/repo/analysis_jingjie/jingjie/autopi_mec_jingjie/autopi_mec/mouse_and_objects_position_tracking/setup_project.py:821: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit()\n",
      "2024-02-13 10:15:56.780332: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 10:15:57.412239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.3...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run setup_project.py\n",
    "import os.path\n",
    "import shutil\n",
    "import cv2\n",
    "from autopipy.dlcObjectDetectors import MouseLEDsDetector\n",
    "from autopipy.cvObjectDetectors import ArenaDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee5f3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating myProject, an autopipy.project object\n",
      "Project name: autopi_mec\n",
      "dataPath: /adata/projects/autopi_mec\n",
      "dlcModelPath: /adata/models\n",
      "Reading /adata/projects/autopi_mec/sessionList_invalid\n",
      "We have 1 testing sessions in the list\n",
      "spikeA.Kilosort_session objects are in sSessions\n"
     ]
    }
   ],
   "source": [
    "projectName, dataPath, dlcModelPath, myProject, sSessions= setup_project_session_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98225f-4cfd-4c71-a73f-a0dc8b08761d",
   "metadata": {},
   "source": [
    "## Check that we have the files we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546461c4-fb78-40e8-b39f-6cc7050feb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ses in sSessions:\n",
    "    ses.load_parameters_from_files() \n",
    "    for t in ses.trial_names:\n",
    "        pfn = ses.path+\"/\"+t+\".positrack2\"\n",
    "        vidfn = ses.path+\"/\"+t+\".mp4\"\n",
    "        for fn in [pfn,vidfn]:\n",
    "            if not os.path.exists(fn):\n",
    "                print(ses.name,fn,\"is missing\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49f8f76-866b-42bb-9b67-69e1fe04c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ses in myProject.sessionList:\n",
    "    fn = ses.fileNames['arena_top.cropped.avi']\n",
    "    if not os.path.exists(fn):\n",
    "                print(ses.name,fn,\"is missing\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af62ea-eea0-4620-946e-fdcdf067395b",
   "metadata": {},
   "source": [
    "# Process the positrack2 files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71e996-741e-4ee3-866d-843ebbc0a3a7",
   "metadata": {},
   "source": [
    "We process the positrack2 video offline. The model takes the full size image and with an old GPU runs at 31 Hz. This is about real-time performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e75c9c-ed43-4abd-9db7-6682cbf23bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ses in enumerate(sSessions):\n",
    "    ses.load_parameters_from_files() \n",
    "    dlcDone=True\n",
    "    for t in ses.trial_names:\n",
    "        pfn = ses.path+\"/\"+t+\".positrack2\"\n",
    "        vidfn = ses.path+\"/\"+t+\".mp4\"\n",
    "        out = ses.path+\"/\"+t+\"DLC_resnet50_positrack2MouseLEDs_540_840Sep29shuffle1_300000.h5\"\n",
    "        if not os.path.exists(out):\n",
    "            dlcDone=False\n",
    "    \n",
    "    if dlcDone == False:\n",
    "        print(i,ses.name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838659ec-f101-4099-acd6-d7180b06a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDirectory=\"/adata/models/positrack2MouseLEDs_540_840-Allen-2022-09-29\"\n",
    "configFile=modelDirectory+\"/config.yaml\"\n",
    "mouseD = MouseLEDsDetector(pathConfigFile=configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6cc1797-7f2a-4a33-b670-fc64c67904c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mn8578-30112021-0107'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses = sSessions[0]\n",
    "ses.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a8aceb-ac12-4148-bb9f-5135068e2b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ses in sSessions[22:23]:\n",
    "    for t in ses.trial_names[4:5]:\n",
    "        pfn = ses.path+\"/\"+t+\".positrack2\"\n",
    "        vidfn = ses.path+\"/\"+t+\".mp4\"\n",
    "        print(pfn)\n",
    "        mouseD.inferenceVideo(pathVideoFile=vidfn,overwrite=True)\n",
    "        mouseD.labelVideo(pathVideoFile=vidfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c09eeb-2468-4f4a-a5fa-adb97e1a359b",
   "metadata": {},
   "source": [
    "Check a few label videos to make sure the quality is ok. It looked pretty good. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f18d7-b3dd-49f4-911a-268595eaeb2a",
   "metadata": {},
   "source": [
    "# Process the arena_top.cropped.avi video to get the animal position\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155886b0-8c8a-4e49-865c-05951dbc64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDirectory=\"/adata/models/arenaTopMouseLEDs_480_480-Allen-2022-09-29\"\n",
    "configFile=modelDirectory+\"/config.yaml\"\n",
    "mouseD = MouseLEDsDetector(pathConfigFile=configFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a580fb-b6a6-4d6a-b625-6d34fd18d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ses in enumerate(myProject.sessionList):\n",
    "    \n",
    "    croppedVideoFile = ses.fileNames['arena_top.cropped.avi']\n",
    "    out = ses.path+\"/\"+ses.name+\".arena_top.cropped\" + \"DLC_resnet50_arenaTopMouseLEDs_480_480Sep29shuffle1_700000.csv\"\n",
    "    #print(out)\n",
    "    if not os.path.exists(out):\n",
    "        print(i,ses.name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a196b2-0206-445e-ad6e-76106c85dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date and time = 13/02/2024 10:16:55\n",
      "Running dlc.analyze_video on /adata/projects/autopi_mec/mn8578/mn8578-30112021-0107/mn8578-30112021-0107.arena_top.cropped.avi\n",
      "Using snapshot-700000 for model /adata/models/arenaTopMouseLEDs_480_480-Allen-2022-09-29/dlc-models/iteration-0/arenaTopMouseLEDs_480_480Sep29-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilo/miniconda3/envs/spikeA/lib/python3.11/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2024-02-13 10:16:57.865998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:57.869620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:57.869784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:57.870894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:57.871072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:57.871159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:58.335735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:58.335934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:58.336031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-13 10:16:58.336100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 131 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-02-13 10:16:58.356960: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2024-02-13 10:16:58.647552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 131.44MiB (137822208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.943085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.943492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.943932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.944287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.944696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.945080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.945489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.945853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.946295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.946671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.947077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.947466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.947820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.948237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.948593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.948954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.949336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.949752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.950109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.950529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.950893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.951275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.951643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.952019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.952391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.952758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.953136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.953503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.953870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.954236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.954612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.954970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.955399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.955781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.956142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.956502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.956883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.957265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.957620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.957983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.958341: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.958737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.959091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.959669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.960012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.960359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.960747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.961102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.961469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.961832: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.962279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.962661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.963012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.963441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.963862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.964338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.964752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.965297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.965731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.966096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.966461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.967006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.967392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.967783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.968225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.968594: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.968959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.969366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.969736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.970092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.970451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.970810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.971172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.971579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.971939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.972446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.972810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.973216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.973606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.974008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.974411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.974767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.975131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.975524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.975922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.976285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.976643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.976998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.977385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.977737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.978146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.978499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.978896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.979245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.979601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.979977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.980328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.980885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.981246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.981643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.981996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.982368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.982765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.983141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.983511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.984002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.984368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.984761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.985134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.985525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.985892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.986295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.986647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.987047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.987455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.987811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.988162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.988547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.988967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.989347: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.989711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.990115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.990473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.990828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.991214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.991622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.992019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.992373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.992773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.993128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.993488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.993867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.994311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.994714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.995122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.995530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.995956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.996359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.996814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-13 10:16:59.997184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:736] failed to allocate 13.14MiB (13782016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /adata/projects/autopi_mec/mn8578/mn8578-30112021-0107/mn8578-30112021-0107.arena_top.cropped.avi\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_mec/mn8578/mn8578-30112021-0107/mn8578-30112021-0107.arena_top.croppedDLC_resnet50_arenaTopMouseLEDs_480_480Sep29shuffle1_700000.h5\n",
      "dlc.loadPositionData() read data from /adata/projects/autopi_mec/mn8578/mn8578-30112021-0107/mn8578-30112021-0107.arena_top.croppedDLC_resnet50_arenaTopMouseLEDs_480_480Sep29shuffle1_700000.h5\n",
      "Saving position data to /adata/projects/autopi_mec/mn8578/mn8578-30112021-0107/mn8578-30112021-0107.arena_top.croppedDLC_resnet50_arenaTopMouseLEDs_480_480Sep29shuffle1_700000.csv\n",
      "End date and time = 13/02/2024 10:17:03\n"
     ]
    }
   ],
   "source": [
    "for ses in myProject.sessionList[0:45]:\n",
    "    croppedVideoFile = ses.fileNames['arena_top.cropped.avi']\n",
    "    mouseD.inferenceVideo(pathVideoFile=croppedVideoFile,overwrite=False)\n",
    "    #mouseD.labelVideo(pathVideoFile=croppedVideoFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3fd35-87bf-4814-b27d-a9c93902e185",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikeA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
